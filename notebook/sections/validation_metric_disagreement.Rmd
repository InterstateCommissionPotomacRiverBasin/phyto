---
title: "R Notebook"
output: html_document
---

```{r echo=FALSE}
knitr::opts_chunk$set(eval=evaluate, cache=cache.me)
```

### Metric Disagreement


This section compares the values found in this document to the values found by Jacqueline M. Johnson. The previous section was good for identifying issues related to scoring the metrics. This section identifies issues related to the metric values. The discrepancies found here most likely do not have to deal with the formula used to calculate the metrics but probably stem from differences in how the taxonomic counts are prepared.

Values from this document (`ratings.df`) are merged with Jacqueline M. Johnson's values (`old.df`).  Season (`season`) and salinity zone (`salzone`) are combined (`unite()`) to represent phytoplankton index names. Metrics (`metric`), indices (`index`), and data sources (`source`) are converted to factors to make them easier to plot in subsequent code chunks.
```{r}
join.df <- left_join(ratings.df, old.df, by = c("station", "date", "season", "salzone",  "metric")) %>% 
  filter(date <= max(old.df$date)) %>% 
  unite(index, season, salzone) %>% 
  left_join(unique(bay.df[, c("unique_id", "source")]), by = "unique_id") %>% 
  mutate(index = factor(index),
         metric = factor(metric),
         source = factor(source))
```

The numeric values are all rounded to the hundredth place to reduce the detection of minor discrepancies. The absolute difference between the re-calculated IBI score and Jacqueline M. Johnson's IBI score is calculated (`ibi_diff`). Rows are sorted to present IBI score differences in descending order (`ibi_diff`) and only rows where the IBI differences disagree (`ibi_diff > 0`) are retained. This data frame can be used to explore differences in individual metric scores that are causing discrepancies between the two IBI values.
```{r}
join.df <- join.df %>% 
  mutate_if(is.numeric, round, digits = 2) %>% 
  mutate(metric_diff = abs(value - old_metric_value),
         score_diff = abs(score - old_score_value),
         ibi_diff = abs(ibi_score - old_ibi_score)) %>% 
  select(unique_id,  metric, index, source,
         value, old_metric_value, metric_diff,
         score, old_score_value, score_diff,
         ibi_score, old_ibi_score, ibi_diff,
         rating, old_rating)
```

Identify IBI scores calculated in this document that differ from the IBI scores calculated by Jacqueline M. Johnson.
```{r}
diff.df <- join.df %>% 
  filter(ibi_diff > 0) %>% 
  arrange(desc(ibi_diff), desc(score_diff), desc(metric_diff)) %>% 
  distinct()
```

#### Overview of Descrepancies

Focus on just the IBI scores that differ. Categorize the IBI score differences (`ibi_diff`) into bins representing 0.5 increments.
```{r}
diff.ibi <- diff.df %>% 
  select(-metric, -value, -old_metric_value, -metric_diff,
         -score, -old_score_value, - score_diff) %>% 
  mutate(disagree_bin = case_when(
    ibi_diff > 0 & ibi_diff <= 0.5 ~ "0 < IBI Score <= 0.5",
    ibi_diff > 0.5 & ibi_diff <= 1 ~ "0.5 < IBI Score <= 1.0",
    ibi_diff > 1 & ibi_diff <= 1.5 ~ "1.0 < IBI Score <= 1.5",
    ibi_diff > 1.5 & ibi_diff <= 2 ~ "1.5 < IBI Score <= 2.0",
    ibi_diff > 2 & ibi_diff <= 2.5 ~ "2.0 < IBI Score <= 2.5",
    ibi_diff > 2.5 & ibi_diff <= 3 ~ "2.5 < IBI Score <= 3.0",
    ibi_diff > 3 & ibi_diff <= 3.5 ~ "3.0 < IBI Score <= 3.5",
    ibi_diff > 3.5 & ibi_diff <= 4 ~ "3.5 < IBI Score <= 4.0",
    TRUE ~ "ERROR"
  )) %>% 
  distinct() %>% 
  arrange(desc(ibi_diff))
```

If at there is at least one IBI score disagreement, then plot the counts of IBI score disagreement for each index (`index`). The bins created in the previous code chunk can be used to divide up the data into separate plots and provide a little bit more information regarding how much the index scores differ.
```{r , fig.width = 8, fig.height = 6}
if (nrow(diff.ibi) > 0) {
  ggplot(diff.ibi, aes(index, fill = index)) +
    geom_bar() +
    facet_wrap(~ disagree_bin) + 
    xlab("Index") +
    ylab("Number of Discrepancies") +
    coord_flip() 
}
```

Focus just on scores that differ, which makes it easier to identify errors in this documents code. Subset `disagree.df` to only include metrics (`metric`), metric values (`value`), Jacqueline M. Johnson's scores (`old_score_value`), and this documents scored values (`score`). Find the absolute difference (`score_diff`) between Jacqueline M. Johnson's scores (`old_score_value`) and this documents scored values (`score`). Only rows where the scores disagree (`score_diff > 0`) are retained.
```{r}
diff.score <- diff.df %>% 
  select(unique_id, index, source,  metric, value, old_score_value, score) %>% 
  distinct() %>% 
  mutate(score_diff = abs(old_score_value - score)) %>% 
  filter(score_diff > 0)
```

If there is at least one metric score disagreement, plot the counts of score disagreement for each metric.
```{r, fig.width = 8, fig.height = 3}
if (nrow(diff.score) > 0) {
  ggplot(diff.score, aes(metric, fill = metric)) +
    geom_bar() +
    coord_flip()
}
```

If there is at least one metric score disagreement, plot the counts of score disagreement for each metric by index (`index`).
```{r, fig.width = 8, fig.height = 6}
if (nrow(diff.score) > 0) {
  ggplot(diff.score, aes(metric, fill = metric)) +
    geom_bar() +
    coord_flip() +
    facet_wrap(~index, ncol = 4) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(ncol = 2, bycol = TRUE))
}
```

More information can be gleaned from the previous plot if the data source (`source`) is also used as a grouping factor. Counts of score differences are summed by `metric`, `index`, and `source`.
```{r}
diff.score.source <- diff.score %>% 
  group_by(metric, index, source) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  tidyr::complete(metric, index, source) %>% 
  mutate(count = if_else(is.na(count), as.integer(0), count))
```

If there is at least one metric score disagreement for `diff.score.source`, plot the counts of score disagreement for each metric by source (`source`) and index (`index`).
```{r, fig.width = 8, fig.height = 25}
if (nrow(diff.score.source) > 0) {
  ggplot(diff.score.source, aes(metric, count, fill = metric)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    facet_wrap(~index + source, ncol = 2) +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(ncol = 2, bycol = TRUE))
}
```



```{r}
diff.metric <- diff.df %>% 
  select(unique_id, metric, index, value, old_metric_value, metric_diff) %>% 
  filter(metric_diff > 2 | metric_diff < -2)
```



```{r, fig.width = 8, fig.height = 3}
if (nrow(diff.metric) > 0) {
  diff.metric %>% 
    group_by(metric) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(count) %>% 
    mutate(metric = factor(metric, levels = metric)) %>% 
  ggplot(aes(metric, count, fill = metric)) +
    geom_bar(stat = "identity") +
    coord_flip()
}
```

